\documentclass[article,twoside,11pt]{report}


%Images
\usepackage[pdftex]{graphicx}

\usepackage[usenames,dvipsnames]{xcolor}

%In-document links
\usepackage[linktoc=all, colorlinks=true, linkcolor=black, urlcolor=blue, citecolor=black]{hyperref}

\usepackage[default]{lato}
\usepackage[T1]{fontenc}
%\usepackage[default]{gillius2}


%headers and footers
\usepackage{fancyhdr}

\usepackage[margin=1.4in]{geometry}

%more generous box-fitting
\setlength{\emergencystretch}{3em}


%Lists
\usepackage{enumitem}

%URLs
\usepackage{hyperref}



%text representing commands or in-program text
\newcommand{\command}[1]{\texttt{#1}}
%Place an icon inline with the text
\newcommand{\icon}[1]{\includegraphics[height=1em]{icons/raster/#1.png}}
%Place and icon and command text together to represent a button
\newcommand{\button}[2]{\ \command{\icon{#1} #2}}
%Keyboard shortcut combining a modifier key and another key
\newcommand{\shortcut}[2]{\command{#1 + #2}}
%Menu chain
\newcommand{\menu}[0]{$\rightarrow$}

%filesystem path
\newcommand{\file}[1]{\command{#1}}

%code snippets
\newcommand{\code}[1]{\command{#1}}
\newcommand{\class}[1]{{\color{violet} \code{#1}}}

\definecolor{commentcolour}{rgb}{0.1, 0.5, 0.2}
\newcommand{\comment}[1]{{\color{commentcolour} \code{#1} }}

\definecolor{codeblockbackground}{rgb}{0.9, 0.9, 0.9}
\newcommand{\codeblock}[1]{{%
	\vspace{1em}%
	\centering%
	\fcolorbox{white}{codeblockbackground}{%
		\parbox[l]{\textwidth}{%
			
			\code{#1}%
		}%
	}%
	\vspace{1em}%
}}

\newcommand{\tab}{\hspace*{2em}}



%element
\newcommand{\element}[1]{$#1$}

%emphasis
\newcommand{\emphasis}[1]{{\bf #1}}

%placing a screenshot as a figure
\newcommand{\screenshot}[2]{%
\begin{figure}[h!]
\centering\includegraphics[width=0.85\textwidth]{figures/#1.png}
\caption{#2}
\end{figure}
}


%Table of Contents macros
\newcommand{\tocchapter}[1]{\cleardoublepage\chapter*{#1}\addcontentsline{toc}{chapter}{#1}}
\newcommand{\tocsection}[1]{\section*{#1}\addcontentsline{toc}{section}{#1}}
\newcommand{\tocsubsection}[1]{\subsection*{#1}\addcontentsline{toc}{subsection}{#1}}
\newcommand{\tocsubsubsection}[1]{\subsubsection*{#1}\addcontentsline{toc}{subsubsection}{#1}}

\title{Peakaboo 5}
\date{July 27th, 2018}
\author{Nathaniel Sherry, Marina Suominen Fuller}
        

\begin{document}

\renewcommand{\headrulewidth}{0pt}
\lhead[]{}
\rhead[]{}
%\rhead[\includegraphics[height=1em]{title/peakaboo.pdf}]{\includegraphics[height=1em]{title/peakaboo.pdf}}
\fancyhead[C]{
	\includegraphics[height=1em]{title/peakaboo.pdf}
	\includegraphics[height=1em]{title/usersguide.pdf}
}


\pagestyle{empty}



\begin{titlepage}
	\vspace*{\fill}
	\centering
	\includegraphics[height=20em]{title/logo.pdf}\\
	\vspace*{1em}
	\includegraphics[height=4em]{title/peakaboo.pdf}\\
	\vspace*{1em}
	\includegraphics[height=1.5em]{title/usersguide.pdf}\\
	\vspace*{\fill}
	\vspace*{\fill}
\end{titlepage}

\cleardoublepage

\pagestyle{empty}
\setcounter{tocdepth}{1}
\tableofcontents
\addtocontents{toc}{\protect\thispagestyle{empty}}
\cleardoublepage
\setcounter{page}{1}
\pagestyle{fancyplain}



\tocchapter{Introduction}

Peakaboo allows users to identify the spectral origins of an XRF spectrum using a routine that fits all components of the K, L, or M spectrum including escape peaks and pileup peaks, and then plots their spatial intensity distributions as maps. It was originally developed as part of the Science Studio project.

\tocsection{Accepted File Formats}

Out of the box, Peakaboo provides support for XRF data in a plain-text format. 
Peakaboo Plain-Text is a simple XRF format comprised of rows of space-separated 
numbers. Each row represents a single spectrum.

Because of the wide variety of data formats, Peakaboo also makes it easy to create plug-ins for supporting additional data formats. Some examples of file formats supported by plug-ins include Amptek, Sigray, and Inca Emsa. See the section on ``Plugins'' for more information.

Peakaboo also allows users who are familiar with the Java or JavaScript programming languages to add support for new file formats. See the section on ``Extending Peakaboo'' for more information.

\tocsection{Getting Help}

If you have any questions or concerns not addressed in this guide, please feel free to contact the developer at \command{nsherry4@uwo.ca}


\tocchapter{Getting Started}

\tocsection{Opening Data}

Select \button{document-open}{Open} or 
\command{\button{main-menu}{Menu} \menu \button{document-open}{Open}} to locate your XRF data. If all scan point data is contained in a single file, simply select that file and open it. If there are many individual scan point files, (eg one scan per file), then locate them in their directory and use \shortcut{Control}{Click} to select more than one of them, or \shortcut{Control}{A} to select all of them.

\screenshot{open-files}{Peakaboo's file selection dialog}

\tocsection{File Format Conflicts}

While rare, it is possible that more than one of the plug-ins that Peakaboo uses to read XRF data will believe that it can open a particular data set. This is usually the result of many different file formats having some of the same properties, such as similar file extensions (eg \file{.txt}, \file{.dat}, \file{.xml}, \ldots ). In the event that Peakaboo cannot automatically determine which XRF reader plug-in to use, it will ask you to indicate which format your data is in. Select the entry which matches your data.

\tocsection{Viewing the Data}

The \icon{zoom-in} \icon{zoom-out} zoom slider bar on the bottom right of the window allows you to expand the x-axis (energy scale). You can use the scroll bar below the scan (or click and drag on the spectrum itself) to pan back and forth to view different energy regions. 

The \button{misc-locked}{Lock Zoom} button locks the vertical zoom to the size of the viewing area. You can disable this if you wish to zoom in vertically as well as horizontally.

\screenshot{zoom-scroll}{Zoom controls and horizontal scrollbar}


\tocsection{Individual Scans}

The \command{Scan} field on the left side of the status bar, under the spectrum view, allows you to view individual spectra in a map. 

Click on the up and down arrows to select the desired scan, or enter a value and press \command{Enter}. This field will be disabled if you are viewing the mean average or strongest per channel composites rather than individual scans.

\screenshot{scan-number}{Scan number selector}


\tocsection{Energy Calibration}

The \button{energy-menu}{Calibration} menu in the upper right allows you to configure the energy range of the dataset. If your dataset contains these values (and if Peakaboo can read them), the minimum and maximum energy values will be set automatically. If not, you will have to enter them manually. 

These values can be tweaked or adjusted by selecting several major elements known or suspected to be present in the sample and adjusting the energy range until the associated peaks fit properly (See the section on Peak Fitting for more information on adding fittings).

Peakaboo can also try to auto-detect the energy calibration with the \button{auto}{Guess Calibration} tool. You should always review any results from this tool to make sure that they are correct.

You should double-check any energy calibration by adding another element to your fittings. Although \element{Ar} may not be present in your sample, it typically appears in XRF spectra. Select \element{Ar} from the peak list and look for the \element{Ar} K-$\alpha$ peak. It should appear at 2.95 keV with the accompanying K-$\beta$ peak. If you start adding more element lines and the fits appear off, check your calibration again.

\screenshot{max-energy}{The calibration menu}




\tocsection{Customizing the View}

The \command{\button{view-menu}{View}} menu contains many settings to help you visualize the spectrum: \command{Logarithmic Scale}, \command{Axes}, and other settins control how a spectrum is presented. \command{Individual Scan}, \command{Mean per Channel}, and \command{Max per Channel} allow you to view a single scan, the per-channel average scan, or the per-channel maximum values.  These composite modes can be useful for viewing a cleaner spectrum, or for finding elements which only appear in a small area of your dataset.

You can also add curve fitting markings to your spectrum: \command{\button{view-menu}{View} \menu\ Curve Fit \menu\ Element Names} to label each curve with the name of the element it represents, \command{\button{view-menu}{View} \menu\ Curve Fit \menu\ Markings} showing transition markings (K-, L-lines), and \command{\button{view-menu}{View} \menu\ Curve Fit \menu\ Heights} for fitting heights (max counts).

\screenshot{view-example}{Peakaboo with mean averaged data, axes, fitting labels, and fitting markings}

Your spectrum, as it appears in the window, can also be saved by selecting 
\button{device-camera}{Export Plot as Image} from the toolbar or \shortcut{Control}{P}. Image format options include \command{PNG}, \command{SVG} or \command{PDF}. You can also save the fitting results as a text file by selecting \command{\button{main-menu}{Menu} \menu\ Export \menu\ Fittings as Text}.


\tocsection{Saving and Loading Sessions}

You can save your session information so that next time you want to look at an XRF dataset, you can load this information (session) and not have to start from the beginning. You must still load the dataset separately, as the saved session does not store the data itself. These options are found under \command{\button{main-menu}{Menu} \menu\ \button{document-save}{Save Session}} and \command{\button{main-menu}{Menu} \menu\ Load Session}.




\tocchapter{Peak Fitting}


\tocsection{Escape Peaks}

Before doing any peak fitting, you should consider the type of detector you used to collect the XRF spectra. Features may be present in your spectra that are due to incoming X-rays interacting with the detector material. For example, for a \element{Si} detector, there is a probability that some of the incoming X-rays will interact with the \element{Si} and kick out \element{Si} K-shell electrons, thereby reducing the incoming X-ray's measured energy by 1.74 keV. This escape peak may be present for major elements in a sample.

To adjust the type of escape peaks used in fitting the peaks in your spectra, select \command{\button{energy-menu}{Calibration} \menu\ Advanced Options} and choose either \command{Silicon} or \command{Germanium}, depending on the type of detector you used. If you do not need to fit escape peaks, choose \command{None}. By default, \command{Silicon} is selected.

\tocsection{Selecting Fittings}

There are four different tools which can be used to fit your data. To access these options, click on the drop-down arrow next to the \button{edit-add}{Add Fittings} button at the top of the \command{Peak Fitting} tab.


\tocsubsection{Guided Fitting}

Guided fitting will attempt to identify peaks one by one with user supervision. Click on the peak you wish to fit and the program will fit the peak with a possible option. Other possible options will also be displayed in a drop down list in the side bar. To add another fitting, click on the \button{edit-add}{Add} button below the current entry and click on another peak. To edit a previous fitting, click \button{edit-edit}{Edit}. Once you are happy with the fittings click \button{choose-ok}{OK} to add the fittings to your list.

\screenshot{guided-fitting}{The guided fitting controls}


\tocsubsection{Automatic Fitting}

Automatic fitting will attempt to identify all intense peaks at once, without user supervision. Simply selecting this option from the menu will automatically populate the fittings list with suggestions. Take extra care to review these fittings manually, as they are by no means guaranteed to be correct.


\tocsubsection{Element Lookup}

Best results are usually obtained by adding elements with the lowest atomic numbers first and working your way up. It is recommended that you fit the K lines first. L lines for elements for tungsten and higher should be fit separately from the K lines for lower atomic number elements, as the K lines will interfere with the L line fittings. As you select elements, their fittings will appear in red on the spectrum. Once you are happy with the fittings, click \button{choose-ok}{OK}, and the list of newly-fitted elements will be added to your fitted element list, and will appear in black on the spectrum.

\screenshot{lookup-fitting}{The elemental lookup fitting controls}

\tocsubsection{Summation Peaks}

If you are having trouble finding element lines to fit some peaks in your spectrum, you may have what are called `pile-up peaks' (referred to as `summation' peaks in Peakaboo). This is a detector phenomenon. If your sample has a lot of one element present, then some of the emitted x-rays due to the presence of this element will impinge on the detector virtually simultaneously and the pulse created and measured would be the sum of the two x-ray energies. Please note that for element lines to appear in the drop down lists, they must have already been included in the spectral fit.

\screenshot{fitting-summation}{The summation fitting controls}

\tocsection{Working with Fittings}

Each fitting has a checkbox under the \command{Fit} column in the \command{Peak Fitting} panel. This checkbox controls whether this fitting is enabled or not. Toggling the checkbox will allow you to temporarily remove a specific fitting from the fitting process. Rechecking the box will restore the fitting as it was.

When using background filters, it is usually best to leave 10\%-15\% of the background in place (default is 10\%) in order to prevent the background filter from removing all signal under the edges of the peak. When too much signal around the edges of a peak is removed, it can prevent peaks from being fitted to the proper intensity, or being fitted at all.

\tocsubsection{Fitting Algorithms}

When trying to determine how to fit an element's theoretical peak curve to real data, Peakaboo has several algorithms to make this determination. The algorithm can be selected from \command{\button{energy-menu}{Calibration} \menu\ Advanced Options \menu\ Single-Curve Fitting}. The available options are:

\begin{description}

\item [Max-Under-Curve] This is the default algorithm in Peakaboo. It is extremely fast, and quite conservative in fitting against real data. Within a fitting's full-width half-max (FWHM) area, it will never over-fit against real data. The drawback is that it does not handle noisy data particularly well, since any single-channel dip in a curve can keep it from fitting it completely.

\item [Least Squares] This is a standard optimizing algorithm minimizing the sum of the squares of the difference between the fitting's curve and the data. This algorithm is excellent for working with extremely noisy data, but has a tendency to over-fit against curves which are not as strong as it thinks they ought to be.

\item [Optimizing] This is a Least Squares algorithm modified to strongly penalize over-fitting against signal which doesn't exist. It acts as a trade-off between the other two; reasonably good fitting of noisy data and reasonably averse to over-fitting non-existent signal.

\end{description}

\tocsubsection{Multi-Element Fitting Solvers}

When fittings from two or more elements overlap, they content for being fit against the same data. Peakaboo must solve this signal contention by determining how much of the signal originates from each elemental fitting. The algorithm can be selected from \command{\button{energy-menu}{Calibration} \menu\ Advanced Options \menu\ Multi-Curve Solver}. Peakaboo has two algorithms for determining the intensity of each contending fitting:

\begin{description}

\item [Greedy] The Greedy fitting solver is the default fitting solver algorithm in Peakaboo. is extremely fast, and allows the user to control the order of fittings by rearranging the fittings in the side bar. 

It works by scaling each fitting curve, one at a time, using the selected fitting algorithm (described in the previous section). Each curve is fitted against a spectrum with all previously fitted curves subtracted from it. Thus, each curve greedily fits as much signal as it can from the residual spectrum of previous elemental fittings.

While there are usually multiple peaks per fitting which all constrain the height of a fitting, in the case of peak overlap, a fitting will occasionally be calculated to be larger than it ought to be. In this case, other fittings may be under-represented because there is no more signal left for those fittings to be fit to.

Changing the order of fittings can reveal and correct these problems. Select a fitting (\shortcut{Control}{Click} to select several) that you wish to change the ordering of, and click \button{go-up}{Move Up} or \button{go-down}{Move Down} to adjust the ordering of their fitting.


\item [Optimizing] The Optimizing fitting solver is a Least Squares algorithm modified to strongly penalize over-fitting against signal which doesn't exist. This algorithm is slower than Greedy, but results in more nuanced fitting solutions in complex, crowded spectra with many overlapping peaks.

\end{description}


\tocsection{Details of Peak Fitting}

A fitting is a model composed of several ``transitions'' from one of the K, L, or M groups of electronic transitions within the particular atom. The positions and relative intensities for each transition series were taken from several tabulated sources to build a model as accurate and as thorough as possible. Fittings take account of details such as separations and relative intensities of transitions. Most fittings are derived from data from the \href{https://github.com/tschoonj/xraylib}{Xraylib} \cite{xraylib} project. For high $Z$ elements where the K series fittings are available in Xraylib, values provided by Krause 
\cite{krause} have been used. The intensity rations have been optimized for $\sim$20keV irradiation.

For fitting of the spectral peaks, a Pseudo-Voigt fitting function is used by default, with a width which expands slightly as the energy level increases \cite[p.~282]{xray-handbook}. Other peak modelling functions are available from \command{\button{energy-menu}{Calibration} \menu\ Advanced Options \menu\ Peak Model}




\tocchapter{Filters}

\tocsection{Using Filters}

Filters can be accessed by clicking on the \command{Data Filters} sidebar tab and then clicking on \button{edit-add}{Add Filters} to display the available filters. Filters are grouped into types. Each type heading can be expanded by clicking on the expander to the left of the filter type. Select the filter you wish to use and then click \button{choose-ok}{OK} to add it. 

Once you have added the filter, you can modify or check the parameters associated with your filter by clicking on the \button{misc-preferences}{Edit} button next to the filter. This will bring up a settings panel for this filter. As you change the parameters, you will see the changes reflected in the spectrum being displayed. Once you are satisfied with the filter settings, you may close the window.

To view a full listing of built-in filters and their descriptions, see the appendix.

\screenshot{brukner-filter}{The Brukner background filter's settings window with raw data outline in plot}

The use of filters will obviously alter the spectrum. If you wish to see the original spectrum in addition to the filtered data, select \command{\button{view-menu}{View} \menu\ Raw Data Outline}.


\tocsection{Noise Removal}

Noise reduction is essential since the spectra are taken at very brief intervals while the sample is scanned in the X-Ray beam. The software provides a number of mathematical filters that are used in noise reduction or in background attenuation or removal. Noise filters include moving average, fast Fourier transform (FFT) low pass, Savitsky-Golay, and others.

Where applicable, noise removal filter parameters can be adjusted to suit the data in question. Best noise reduction with minimum change in peak shape is often achieved using a Savitsky-Golay filter.


\tocsection{Background Removal}

Background removal or reduction is particularly important for spectra acquired using white radiation. Peakaboo has a number of background removal filters of varying sophistication and performance. Varying levels of background can be removed, but care should be taken not to remove genuine signal along with the background, as this may degrade the peak fitting result.



\tocsection{Filtering Example with Normalizer Filter}

When detector deadtime is very high, the detector cannot keep up with the incoming x-rays. For example, low energy x-rays such as those coming from \element{Ar} may not get counted and mapping the distribution of \element{Ar} will reveal areas of next to no intensity. 

The \command{Normalizer Filer} scales each spectrum so that the intensity at a given channel is always the same. This filter can be used in this case to correct the spectra. By normalizing against a channel from within the \element{Ar} peak, we can mitigate the distortion caused by detector saturation.

Go to the \command{Filters} tab and add the \command{Normalizer Filter} found under the \command{Advanced} filter types. Click on the \button{misc-preferences}{Settings} button to bring up the settings window for the filter. Place the cursor on the \element{Ar} peak in the spectrum and read the channel number and value (counts) from the information found below the spectrum window, and enter them into the appropriate settings fields. Make sure you are viewing the \command{Mean Average} spectrum to get the average value (counts) for the \element{Ar}. Close the edit window.

\clearpage
\screenshot{normalize-uncorrected-ar}{Uncorrected \element{Ar} with weak signal where \element{Ti} is strongest} \screenshot{normalize-uncorrected-ti}{Uncorrected \element{Ti}} \screenshot{normalize-corrected-ar}{Corrected \element{Ar}} \screenshot{normalize-corrected-ti}{Corrected \element{Ti} with greater maximum intensity}



\tocchapter{Mapping}

To map the fitted elements, click on \button{map}{Map Fittings} in the toolbar. Only those fittings which are enabled in your \command{Peak Fitting} list will be mapped. It is recommended that you enable all fittings for mapping as each fitting results in an individual map which can be disabled later.

\screenshot{map-window}{Peakaboo's mapping window}

Once the mapping is complete, a window will appear with a coloured map, scale, and list of mapped element lines. For datasets which contain dimension information, map widths and heights are automatically set to appropriate values. Otherwise, the user must adjust the width and height. 

All fittings will be represented in the initial map. To get the individual element maps, uncheck all other fittings in the \command{Peak Fittings} tab in the sidebar, leaving the element fitting you wish to view. If your maps have a pixelated appearance, you may want to try interpolating the data and using contouring. Note that interpolation is not adding new data to the map, and should not be used to excess.

Maps are generally scaled against a global maximum of all fittings. If you wish to scale a fitting to its own highest intensity, select \command{Visible Fittings} under the \command{Peak Fittings} sidebar tab. If you choose the \command{All Fittings}, then the maps will be scaled to the highest intensity from the sum of all fittings. A minor element will show very a low intensity distribution with the latter option, but appear much more intense with the former.

Maps may be saved by clicking the \button{device-camera}{Save Image} button on the toolbar. Various formats are available for saving your element line maps, Pixel Image (\command{PNG}), Vector Image (\command{SVG}) and \command{PDF} format.


\tocsection{Overlays}

The \command{Overlay} option for mapping is chosen from the drop down list under \command{Peak Fittings} sidebar tab. This allows you to sort fittings into four groups: 

\begin{itemize}[topsep=4pt,itemsep=1pt,partopsep=0pt, parsep=0pt]
\item \command{Red}
\item \command{Yellow}
\item \command{Green}
\item \command{Blue}
\end{itemize}

These groups are overlaid, with the presence of each colour indicating the intensities of their fitting groups. Because Red, Green, and Blue are the primary colours for computer displays, using all four colours can introduce ambiguity, and care should be taken when making selections.

\screenshot{map-overlay}{Overlay of Iron and Zinc concentration}

The \command{Scale Colours} options control the way that the fitting group's colours are scaled. With the \command{As a Group} option, the highest intensity from \emphasis{all} groups of fittings is used to scale the intensities for \emphasis{every} group. With the \command{Separately} option, the highest intensity from \emphasis{within each} group of fittings is used to scale the intensities for that group. The \command{Separately} option produces maps which may be qualitatively interesting, but are quantitatively 
incorrect.

\tocsection{Ratios}

Mapping of element ratios is also available within Peakaboo. Select \command{Ratio} from the \command{Peak Fittings} dropdown list. Select the fittings (or fitting sets) you wish to view in ratio and select the desired colours from the dropdown lists next to each fitting.

\screenshot{map-ratio}{Ratio of Iron and Zinc}

\tocsection{Errant Data}

Missing or skewed spectra within a data set can be removed from the map. Hover the mouse over the bad data point in the mapping window, and the index of that data point will appear in the status bar at the bottom of the window. To view the errant data point, return to the plotting window, making sure you are in \command{Individual Scan} mode, and enter the \command{Index \#} of the invalid data in the \command{Scan} field at the bottom of the window. 

Click on the \button{choose-cancel}{Exclude} button to flag the scan as bad, and to  exclude it from the data set. In all future maps, this data point will be interpolated from neighbouring data.


\tocsection{Selecting Subsections}

There are two ways to select sections of a map, cropping and point-selection. Cropping is accomplished by clicking and dragging on the map to create a selection mask. 

\screenshot{select-subset}{Selecting a cropped subset of a data set}

Point selection is accomplished by double clicking on a point of interest, which will select all points in a contiguous region with similar intensity. Triple clicking will select all points in a map with similar intensity regardless of location. More complex selections can be made by holding the \command{Control} key while double-clicking.

\screenshot{select-points}{Selecting a series of contiguous high-intensity points from the data set}

\tocsection{Examining Subsections}

The distribution of elements will likely vary across your sample and hence your maps. For samples that have a composition that consists primarily of low atomic number (low $Z$) elements, it is possible to make a rough estimate of the composition. This estimate is based on the relative intensities of many elements (from $Z=20\ldots 44$) measured in a glass matrix. The relative intensities of these elements have been entered into Peakaboo as conversion coefficients. Using these coefficients the concentration of elements within a low $Z$ matrix can be estimated.


Left click and drag the mouse in order to draw a rectangle surrounding the region you wish to select. To view the relative intensity information, click on \button{badge-info}{Get Intensities} in the mapping window toolbar.

\screenshot{intensity-estimate}{Rough estimate of elemental intensity in the selected region}

\tocsection{Plotting Subsections}

Peakaboo also allows you to view spectra from selected regions within your map. Using the same technique as described above to select a subsection of your data, click \button{view-subset}{Plot Region} to view the spectra for the selected region. Another tab in the plotting window will open up to display the spectra from the selected region or subset. The spectra can then be processed with Peakaboo.

\screenshot{plot-subset}{Plotting window showing data for a subset of the original data set}


\tocchapter{Plugins}

Plugins can add new filters or new file format support to Peakaboo. You can manage Peakaboo's plugins by selecting \command{\button{main-menu}{Menu} \menu\ Plugins}.

\screenshot{plugins}{Peakaboo's plugin management screen}

\tocsection{Importing New Plugins}

You can import new plugins to Peakaboo in three ways. 

\begin{description}

\item [Import Plugins Button] Clicking the \button{edit-add}{Import Plugins} button will open up a file browser so that you may select the plugin archive that you wish to import. 

\item [Drag and Drop] If you drag and drop plugin archives onto the plugin management screen, Peakaboo will import them for you automatically.

\item [Manually] If you click the \button{document-open}{Open Plugins Folder} button, Peakaboo will open its plugins folder in a file browser. You can manage your plugins manually by adding or removing files. Be sure to update Peakaboo by clicking the \button{action-refresh}{Reload Plugins} button after you're done.

\end{description}

\tocsection{Removing Existing Plugins}

To remove a plugin, select it in the plugins list on the left side of the plugin management screen, then click the \button{edit-remove}{Remove Plugins} button. Be aware that if the plugin is contained in an archive along with other plugins, those other plugins will be removed as well.

\tocsection{Updating to Newer Versions}

You can install updates to existing plugins the same way as you would install a new plugin. If Peakaboo detects that the new plugin is an upgrade, or that the filename matches an existing plugin archive, it will prompt you to replace, rather than add, the plugin.

Sometimes having two version of a plugin may be unavoidable. When Peakaboo detects two versions of a plugin, it will use the version which has the higher version number.

\cleardoublepage
\appendix

\chapter{Extending Peakaboo}

Peakaboo allows users who are familiar with the Java programming language to extend its functionality by creating custom filters and adding support for new file formats. Users who are interested in developing extensions for Peakaboo will need to make sure they have the Java Development Kit (JDK) installed on their computer (available from \href{http://java.com}{Java.com}). A dedicated code editor, such as Eclipse, is also recommended. 

Plugins in Peababoo are classes which implement a specific interface. The interface in question depends on the kind of plugin being created. These plugin classes should be bundled in \file{.jar} files and placed in the correct plugin folder inside of the user's application data directory. For example, on Linux, this path is \file{\textasciitilde/.config/Peakaboo5/}. You can access this folder by selecting \command{\button{main-menu}{Menu} \menu\ Plugins \menu\ Open Folder}.

In order to know which classes to load without scanning each class in every jar file, a jar containing a plugin must include a manifest file, located at \file{META-INF/services/} under the root of the jar file. The file name must be the qualified name of the interface that this type of plugin implements, and the contents of the file must be the qualified names of each class to be 
loaded as a plugin, one per line.

The specific interfaces used for different types of plugins are:
\begin{itemize}[topsep=4pt,itemsep=1pt,partopsep=0pt, parsep=0pt]
\item Data Source: \class{peakaboo.datasource.plugin.JavaDataSourcePlugin}
\item Data Sink: \class{peakaboo.datasink.plugin.JavaDataSinkPlugin}
\item Filter: \class{peakaboo.filter.plugin.JavaFilterPlugin}
\end{itemize}

Example plugins for both filters and data sources are available online at 
\href{http://sciencestudioproject.com/}{sciencestudioproject.com}, along with a jar file containing Peakaboo for building against.

\tocsection{Filters}

Custom filters must implement \class{JavaFilterPlugin}, and for convenience may also extend the \class{AbstractSimpleFilter} or \class{AbstractBackgroundFilter} classes, and should either not define a constructor, or define a \code{public} no-argument constructor.

\tocsubsection{Parameters}

Filters define a series of \class{Parameter}s, each with an associated data type. These parameters are displayed in the filter's settings panel, using the associated data types and class information to determine what kind of widgets should be used. These parameters should be created and initialized in 
the filter's \code{initialize} method.

Once constructed, the parameter should be passed to the \code{addParameter} method of the superclass. This method returns an integer value which you can use to retrieve the parameter later using \code{getParameter(int index)}. The alternative is to simply keep local references to all your \class{Parameter}s. Here is an example of the \code{initialize} method of the \class{Addition} filter:

\codeblock{%
@Override\\
public void initialize()\\
\{\\
\tab Parameter<Float> add = new \class{Parameter<>}(\\
\tab\tab "Amount to Add", \ \ \ \ \  //Human-readable name\\
\tab\tab new \class{RealStyle()}, \ \ \ \ \  //Style hint for UI generation\\
\tab\tab 1.0f, \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  //Starting value\\
\tab\tab this::validate);\ \ \ \ \ \  //validation function\\
\\
\tab addParameter(add);\\
\}
}

This creates a new \class{Parameter} called ``Amount to Add'' with a Float data type, a default value of 1.0, and a validation function defined elsewhere in the class body. It then adds it to this filter's set of parameters.

\tocsubsection{Validation}

Whenever the user makes changes to a filter's parameter value in the \button{misc-preferences}{Settings} dialog, the new parameter value is validated in a call to the parameter's validator method. In the example above, the parameter's validate method is in the filter itself, and could be used by other parameters to validate combinations of values.

If the parameter values do not validate, then the values of the input fields are reset to their old values.


\tocsubsection{Processing Spectra}

An active filter's \code{filter(\class{ReadOnlySpectrum} data)} method is called repeatedly. This method should return a modified \class{Spectrum} containing the results of filtering the input \class{ReadOnlySpectrum}.

The \class{Spectrum} and \class{ReadOnlySpectrum} classes have a \class{List}-like interface, but use a fixed-size \class{float} array to store the actual data for memory and performance reasons.  If you prefer to work with the \class{float[]} data directly, the \code{backingArray} method provides direct access to it.

\tocsection{File Formats (Data Sources)}

Adding support for new file formats in Peakaboo is accomplished by creating a new Data Source. When creating a new data source, the \class{JavaDataSourcePlugin} interface must be implemented. The implementation should either not define a constructor, or define a \code{public} no-argument constructor. A Data Source has a number of methods to retrieve other data structures, some of which are \class{Optional}.

\tocsubsection{File Format}

The \class{FileFormat} interface is how a Data Source describes the type of files it reads and tests if it can read specific files. When the user opens one or more files, Peakaboo must determine which Data Source plugin(s) may be used, and it relies on the Data Source's FileFormat to inform it.

For convenience, the \class{SimpleFileFormat} class provides an easy way to get started, with file-extension based testing and the ability to specify single or multi-file support. Because many data sources use very common file extentions (e.g. \command{.dat}) or container files (e.g. \command{HDF}), developers should consider implementing proper testing through an examination of a file's contents.


\tocsubsection{Reading the Data}

Once your data source has been selected, the \code{void read(\class{List}<\class{Path}> paths)} method will be called at most once. The paths given here will be the same as the paths tested for compatibility through the supplied \class{FileFormat}, so there is no need to recheck the files.

Because Peakaboo is an interactive desktop application, progress should be reported to the user through the \class{Interaction} class. The Data Source interface defines get/set methods for this object, and this object will be set before the data is read. It contains several methods which can be used to report progress or allow user control.

\codeblock{%
boolean checkReadAborted()\\
void notifyScanCount(\class{int} scanCount)\\
void notifyScanRead(\class{int} number)
}

The \code{checkReadAborted} method checks to see if the user has decided to abort the read operation. This method should be checked periodically, and if it returns \code{true}, the read operation should be halted. The data source instance will not be used after the user has requested the read to be aborted, so there is no need to worry about any inconsistent state caused by aborting the read. Any open files should still be closed.

The \code{notifyScanCount} method reports the number of scans in the data set to the user interface. The \code{notifyScanRead} method reports that a certain number of new scans have been read since it was last called. These two methods used together allow Peakaboo to show the progress of the read operation to the user. In some file formats, it is not feasible to determine the number of scans in advance of reading them. In this case, simply do not call either of these methods, and the interface will show a ``busy'' indicator instead.


\tocsubsection{Accessing the Data}

Once the \code{read} method has been called, your data source will need to provide access to the data. This is achieved through the \class{ScanData} interface. For convenience, the \class{SimpleScanData} class is provided. It is \emph{highly} recommended that the \class{SimpleScanData} class be used in most cases, as it provides a number of 
performance and memory footprint optimizations. Other implementations of \class{ScanData} should study the \class{SimpleScanData} implementation for an idea of how to achieve these for themselves.


\tocsubsection{Providing Extended Information}

Each data source reads from different kinds of files, which contain different kinds of information about the scan. Further information can be exposed through the \class{DataSize}, \class{PhysicalSize}, and \class{Metadata} 
interfaces, which are all access through the \class{DataSource} interface as \class{Optional} values.


\chapter{Filter Descriptions}

Because Peakaboo uses a plug-in system for fitlers, this cannot be an exhaustive list, but it does cover all built-in filters.

\tocsection{Background Filters}

\tocsubsection{Brukner}

This filter removes background over several iterations by smoothing the data and 
taking the minimum of the unsmoothed and smoothed data for each channel on each pass.

\tocsubsection{Linear Trim}

This filter examines all pairs of points which are $n$ channels apart (ie $(1, 10), 
(2, 11)$, \ldots\ where $n = 10$). For each pair of points, any signal which exceeds a straight line connecting the two points is truncated.

\tocsubsection{Polynomial}

This filter attempts to fit a series of parabolic (or higher order single-term) curves under the data, with a curve centred at each channel, and attempting to make each curve as tall as possible while still staying completely under the spectrum. The union of these curves is calculated and subtracted from the original data.

\tocsubsection{Square Snip}

This is a very fast background removal method based on the Peak Stripping algorithm. It iteratively replaces signal with the average of the points $(-window, +window)$ channels apart if that average is less than the existing signal. By taking a double square root of the signal and then reversing it afterwards, the number if iterations required is greatly reduced. Because noise-reduction filters are separate and composable, this version of the algorithm does not do any smoothing of it's own.



\tocsection{Noise Filters}


\tocsubsection{Fourier Low-Pass}

This filter transforms the spectral data with a Fourier Transformation into a 
frequency domain. Data from a high frequency range (noise) is filtered out, 
while lower frequencies (peaks, background) are passed through.


\tocsubsection{Weighted Averaging}

This filter refines the values of each point in a scan by sampling it and the 
$n$ points to either side of it, and replacing it with an exponentially weighted average of the sampled points.


\tocsubsection{Savitsky-Golay}

This filter attempts to remove noise by fitting a polynomial to each
point $p_i$ and its surrounding points $p_{i-n} \ldots p_{i+n}$, and then taking the value of the polynomial at $p_i$. This filter is generally fast, while minimizing peak distortion. A moving average may be considered a special case of this filter with a polynomial of order 1.


\tocsubsection{Spring Smoothing}

This filter operates on the assumption that weak signal should be smoothed more 
than strong signal. It treats each pair of adjacent points as if they were
connected by a spring. With each iteration, a tension force draws neighbouring
points closer together.

The \command{Force Multiplier} controls how strongly a pair of points are pulled together, and the \command{Force Falloff Rate} controls how aggressively stronger signal is anchored in place, unmoved by tension forces. This prevents stronger intensity points such as peak shapes from being distorted by the smoothing algorithm.


\tocsubsection{Wavelet Low-Pass}

This filter attempts to reduce high-frequency noise by performing a Wavelet transformation on the spectrum. This breaks the data down into sections each representing a different frequency range. The high-frequency regions are then smoothed, and a reverse transform is applied.


\tocsubsection{Low Statistics}

This filter smooths signal per-channel by shrinking a moving-average window until either: 
\begin{itemize}[topsep=4pt,itemsep=1pt,partopsep=0pt, parsep=0pt]
	\item The signal in the window is less than Max Signal
	\item Both of the following are true:
	\begin{itemize}[topsep=4pt,itemsep=1pt,partopsep=0pt, parsep=0pt]
		\item The signal in the window is less than Threshold x sqrt(centerpoint)
		\item The slopes of the left vs. right windows is less than Max Slope
	\end{itemize}
\end{itemize}






\tocsection{Mathematical Filters}

\tocsubsection{Add}

This filter adds a constant value to all points on a spectrum.

\tocsubsection{Subtract}

This filter subtracts a constant value to all points on a spectrum.

\tocsubsection{Multiply}

This filter multiplies all points on a spectrum by a constant value.

\tocsubsection{Derivative}

This filter transforms the data such that each channel represents the
difference between itself and the channel before it.

\tocsubsection{Integral}

This filter transforms the data such that each channel represents the sum of
itself and all channels prior to it.


\tocsection{Advanced Filters}

\tocsubsection{Normalizer}

This scales each spectrum so that the intensity at a specified channel is
always the same across all spectra.

\tocsubsection{Filter Partial Spectrum}

This filter allows the application of another filter to a portion of a spectrum.


%\bibliographystyle{plain}
%\bibliography{manual}

\begin{thebibliography}{9}

\bibitem{xraylib}
	https://github.com/tschoonj/xraylib

\bibitem{krause}
	M.O. Krause, C.W. Nestor, C.J. Sparks and E. Ricci,
	\textit{X-Ray Fluorescence Cross Sections for K and L X Rays of the elements}, 
	Oak Ridge Report ORNL-5399, 
	1978.

\bibitem{xray-handbook}
	Rene E. Van Grieken, Andrzej A. Markowicz,
	\textit{Handbook of X-Ray Spectrometry},
	Marcel Dekker, Inc.,
	Second Edition,
	2002

\end{thebibliography}



\end{document}

